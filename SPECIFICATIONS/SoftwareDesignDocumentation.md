# Cat Flap Stats Software Design Documentation

- Last updated: 2025-06-26
- Updated by: Claude (Magnus collaboration)
- Status: **PRODUCTION V1.0 SYSTEM** - Fully operational with 1,573+ processed records

## Overview

This document contains technical implementation details for the Cat Flap Stats production system. What started as a "basic web dashboard" has evolved into a comprehensive behavioral analytics platform with advanced circadian rhythm analysis, automated processing pipelines, and sophisticated data management.

**Production Status**: Live at https://cat-flap-stats.herrings.workers.dev with automated PDF processing, real-time analytics, and email notifications.

## Quick Start for New Developers

### Prerequisites
- Python 3.13+ installed
- Git access to repository
- Basic understanding of PDF processing and data analysis

### 5-Minute Setup
```bash
# 1. Clone and setup environment
git clone [repository-url]
cd cat-flap-stats
python -m venv venv
source venv/bin/activate  # Required before any Python execution
pip install -r requirements.txt

# 2. Test the system
python -m pytest test_cat_flap_extractor.py -v

# 3. Process a sample PDF
python3 cat_flap_extractor_v5.py SAMPLEDATA/sample1.pdf --debug

# 4. Examine the output
ls temp_outputs/  # Check generated CSV/JSON files
```

### Key Files to Understand First
1. **`cat_flap_extractor_v5.py`** (1,155 lines) - Main extraction engine
2. **`master_dataset.csv`** - Live production data (1,573 records)
3. **`cloudflare-workers/index.js`** - Web application frontend
4. **`.github/workflows/process-pdf.yml`** - Automated processing pipeline
5. **`test_cat_flap_extractor.py`** - Test suite for validation

### Understanding the Data Flow
```
User uploads PDF → CloudFlare Workers → GitHub Actions → Python Extractor → 
Data Processing → Duplicate Detection → Analytics Computation → 
Dataset Update → Git Commit → Email Notification
```

## System Architecture

### Core Components (Production Implementation)

**✅ PDF Processing Engine (1,155 lines)**
- **File**: `cat_flap_extractor_v5.py` - Production-ready extractor with `ProductionCatFlapExtractor` class
- **Features**: Cross-page table reconstruction, mathematical exit/entry determination, cross-midnight detection
- **Validation**: 100% accuracy against manually corrected reference data

**✅ Web Application (29,685+ tokens)**
- **File**: `cloudflare-workers/index.js` - Full-featured dashboard with Material UI
- **Pages**: `/dashboard`, `/patterns`, `/circadian`, `/upload` with drag-and-drop interface
- **Authentication**: Magic link system for authorized users
- **Analytics**: Real-time behavioral pattern analysis and data visualization

**✅ Automated Processing Pipeline**
- **Workflow**: `.github/workflows/process-pdf.yml` (334 lines) - Complete automation
- **Features**: PDF download, testing, extraction, duplicate detection, analytics computation, backup, email notifications
- **Integration**: CloudFlare Workers → GitHub Actions → Git version control

**✅ Data Management System**
- **Live Dataset**: `master_dataset.csv` (1,573 records), `master_dataset.json`
- **Backups**: `dataset_backups/` with automatic pruning (keeps 3 most recent)
- **Source Data**: 65+ production PDFs in `BULK_PRODUCTIONDATA/`

### Technology Stack

#### Development Environment
- **Python**: 3.13 in virtual environment (`venv`)
- **Virtual Environment Location**: `cat-flap-stats/` directory
- **Activation Command**: `source venv/bin/activate` (required before any Python execution)

#### Production Dependencies (`requirements.txt`)
```python
pdfplumber==0.11.7    # Primary PDF processing - excellent table extraction
pandas==2.3.0         # Data manipulation and CSV/JSON export
PyPDF2==3.0.1         # PDF utilities and backup processing
tabula-py==2.10.0     # Alternative table extraction
pytest==8.3.4         # Testing framework
pytest-mock==3.14.1   # Test mocking capabilities
pytest-cov==6.0.0     # Coverage reporting
```

#### Testing Infrastructure (Production-Grade)
- **Test Suite**: 62 tests with 58% coverage across multiple files
- **Daily Testing**: Automated GitHub Actions workflow
- **Test Files**:
  ```
  test_cat_flap_extractor.py      # Main extractor validation
  test_critical_functionality.py  # Critical function protection
  test_merge_datasets.py          # Dataset merging validation
  test_backup_system.py           # Backup system testing
  test_long_duration_fix.py       # Duration parsing edge cases
  ```
- **Test Types**:
  - **Unit Tests**: Duration parsing, timestamp analysis, exit/entry rules
  - **Integration Tests**: PDF processing, data validation, cross-year boundaries
  - **End-to-End Tests**: Full pipeline workflow, output format consistency
  - **Regression Tests**: Critical functionality protection against breaking changes

#### Production Infrastructure
- **CloudFlare Workers**: Full-featured web application with Material UI (29,685+ tokens)
- **CloudFlare KV Storage**: Session management, temporary PDF storage, processing state
- **GitHub Actions**: Automated workflows with comprehensive error handling
- **GitHub Repository**: Version-controlled datasets with automatic backups
- **Webhook Integration**: CloudFlare → GitHub communication for processing triggers
- **Email Notifications**: Resend API integration for processing status reports
- **Configuration**: `wrangler.toml` with KV bindings and environment variables

## Development Commands

### Environment Setup
```bash
# Activate virtual environment (REQUIRED before any Python execution)
source venv/bin/activate

# Install production dependencies
pip install -r requirements.txt
```

### PDF Processing (Production Extractor)
```bash
# Run main extractor (cat_flap_extractor_v5.py - 1,155 lines)
python3 cat_flap_extractor_v5.py [pdf_path] [options]

# Output formats and options
python3 cat_flap_extractor_v5.py [pdf_path] --format csv --output filename.csv
python3 cat_flap_extractor_v5.py [pdf_path] --format json --output filename.json
python3 cat_flap_extractor_v5.py [pdf_path] --format both

# Debug extraction with detailed logging
python3 cat_flap_extractor_v5.py [pdf_path] --debug

# Bulk processing (handles 65+ PDFs)
python3 cat_flap_extractor_v5.py [directory_path] --format csv
```

### Testing (Comprehensive Suite)
```bash
# Run full test suite (62 tests, 58% coverage)
python -m pytest -v --cov=cat_flap_extractor_v5

# Run specific test files
python -m pytest test_cat_flap_extractor.py -v
python -m pytest test_critical_functionality.py -v
python -m pytest test_merge_datasets.py -v

# Coverage reporting
python -m pytest --cov-report=html
```

### Data Management
```bash
# Merge datasets with duplicate detection
python .github/scripts/merge_datasets.py [new_data.csv]

# Compute analytics for JSON export
python .github/scripts/compute_analytics.py

# Rebuild JSON dataset
python .github/scripts/rebuild_json_dataset.py
```

### CloudFlare Workers Deployment
```bash
# Deploy web application
npx wrangler deploy

# Test locally
npx wrangler dev
```

## PDF Extraction System (`cat_flap_extractor_v5.py`)

### Production Implementation (1,155 lines)
- **Class**: `ProductionCatFlapExtractor` - Enterprise-grade extraction engine
- **Processing Capability**: 65+ production PDFs successfully processed
- **Data Scale**: 1,573 validated session records in master dataset
- **Date Range**: Cross-year processing (2024-02-05 to 2025-06-22)

### Advanced Features
- **Cross-page table reconstruction**: Seamlessly handles PDF tables split across multiple pages
- **Cross-midnight session detection**: Rules 3b/4b for complex overnight patterns
- **Cross-year boundary handling**: Sophisticated December-January transition processing
- **Mathematical precision**: Duration-based exit/entry determination with ±30 minute tolerance
- **Edge case handling**: No-data periods, incomplete weeks, partial timestamps
- **Validation accuracy**: 100% tested against manually corrected reference data
- **Bulk processing**: Handles directories with automatic progress reporting

### Architecture Decisions

#### PDF Parsing Library Choice
**Selected**: pdfplumber
**Reason**: Superior table structure extraction capabilities, excellent handling of complex layouts

#### Data Processing
**Selected**: pandas
**Reason**: Robust data manipulation and export capabilities, industry standard

#### Output Formats
**Selected**: CSV and JSON
**Reason**: Maximum compatibility with analysis tools, transparent data structure

#### System Architecture
**Selected**: Single-file extractor with modular class structure
**Reason**: Maintainability while keeping deployment simple

## Exit/Entry Time Determination Rules (Production Implementation)

The `ProductionCatFlapExtractor` class implements mathematically precise rules to determine exit/entry times. These rules have been validated against manually corrected reference data with 100% accuracy across 1,573 production records.

### Rule Classification System

Each outdoor session has:
- **Exit time**: When the cat goes outside through the flap
- **Entry time**: When the cat comes back inside through the flap
- **Duration**: Time spent outside during that session

### Implementation Rules

#### Rule 1: Complete Sessions (Two Timestamps)
If a session has two timestamps with a duration (format: "HH:MM - HH:MM"):
- **First timestamp = EXIT time**
- **Second timestamp = ENTRY time**

Example: `06:01 - 07:39` with duration `01:38 h`
- Exit: 06:01, Entry: 07:39, Duration: 1h 38min

#### Rule 2: Single Timestamp Analysis
For sessions with only one timestamp, use duration analysis to determine the timestamp type.

#### Rule 3: Morning Single Timestamp (Before 12:00) with Short Duration
If timestamp is before 12:00 (midday) AND duration < 12 hours:
- **If duration ≈ time since midnight → ENTRY**
- **Otherwise → EXIT**

Example: `00:21` with duration `21:40 mins`
- 00:21 = 21 minutes after midnight
- Duration = 21 minutes 40 seconds
- Since duration ≈ time since midnight → **ENTRY** (cat was outside overnight, came in at 00:21)

#### Rule 3b: Morning Single Timestamp (Before 12:00) with Long Duration
If timestamp is before 12:00 (midday) AND duration ≥ 12 hours:
- **If duration ≈ time since preceding midnight → ENTRY**
- **If duration ≈ time until following midnight → EXIT**
- **Otherwise → fallback to ENTRY**

#### Rule 4: Afternoon/Evening Single Timestamp (After 12:00) with Short Duration
If timestamp is after 12:00 (midday) AND duration < 12 hours:
- **If duration ≈ time until midnight → EXIT**
- **Otherwise → ENTRY**

#### Rule 4b: Afternoon/Evening Single Timestamp (After 12:00) with Long Duration
If timestamp is after 12:00 (midday) AND duration ≥ 12 hours:
- **If duration ≈ time since preceding midnight → ENTRY**
- **If duration ≈ time until following midnight → EXIT**
- **Otherwise → fallback to EXIT**

#### Rule 5: Cross-Midnight Session Detection
When consecutive days have single timestamps that form overnight sessions:
- **Last timestamp of day + duration ≈ time to midnight = EXIT**
- **First timestamp of next day + duration ≈ time from midnight = ENTRY**

#### Rule 6: Missing Data Handling
If there are gaps in data (missing days/files):
- Cannot determine session continuity across gaps
- Apply rules 3/4/7 to timestamps before/after gaps
- Do not count missing time in duration calculations

#### Rule 7: Fallback Rules (Ambiguous Cases)
When other rules cannot determine timestamp type:
- **Rule 7a**: Morning timestamp (< 12:00) → assume **ENTRY**
- **Rule 7b**: Afternoon/evening timestamp (≥ 12:00) → assume **EXIT**

#### Rule 8: Validation Checks
After extraction:
- **Duration validation**: Sum of session durations should be within ±10 minutes of daily total
- **Session count validation**: Number of complete sessions should be within ±1 of reported daily visits
- **State consistency**: Exit/entry balance should be maintained across days

### Production Implementation Parameters
- **Duration Formats**: "HH:MM h", "MM:SS mins", "SS s" (all formats tested)
- **Precision Tolerance**: ±30 minutes for duration matching rules
- **Cross-Midnight Detection**: Automatic pairing across consecutive days (Rules 5/7)
- **Cross-Year Processing**: December-January boundary handling implemented
- **Error Handling**: Graceful degradation with comprehensive logging
- **Production Validation**: 478 duration-based corrections applied automatically
- **Edge Cases**: No-data periods, incomplete weeks, partial timestamps handled

## Development Workflows

### Adding New Features
1. **Create feature branch**: `git checkout -b feature/new-analytics`
2. **Write tests first**: Add to appropriate test file in test suite
3. **Implement feature**: Modify `cat_flap_extractor_v5.py` or web components
4. **Run test suite**: `python -m pytest -v --cov=cat_flap_extractor_v5`
5. **Test with sample data**: Process PDFs in `SAMPLEDATA/`
6. **Update documentation**: Modify this file with implementation details
7. **Submit for review**: Ensure all tests pass before merge

### Processing New PDF Data
1. **Via Web Interface** (Recommended):
   - Visit https://cat-flap-stats.herrings.workers.dev
   - Login with magic link
   - Upload PDF via drag-and-drop
   - System automatically processes and emails results

2. **Via Command Line** (Development):
   ```bash
   # Process single file
   python3 cat_flap_extractor_v5.py path/to/new.pdf --format both
   
   # Merge with master dataset
   python .github/scripts/merge_datasets.py temp_outputs/new_data.csv
   ```

### Troubleshooting Common Issues

#### PDF Processing Failures
- **Check PDF structure**: `python3 cat_flap_extractor_v5.py problem.pdf --debug`
- **Validate table extraction**: Look for "Last 7 days" table on page 2
- **Review error logs**: Check detailed logging output for parsing issues
- **Test with samples**: Compare against working PDFs in `SAMPLEDATA/`

#### Test Failures
- **Run specific test**: `python -m pytest test_cat_flap_extractor.py::TestDurationParsing -v`
- **Check coverage**: `python -m pytest --cov-report=html`
- **Review regression**: Compare against previous working state
- **Validate test data**: Ensure test PDFs haven't been corrupted

#### Data Quality Issues
- **Check validation**: Review `master_dataset.csv` for anomalies
- **Examine backups**: `dataset_backups/` contains recent versions
- **Run analytics**: `python .github/scripts/compute_analytics.py`
- **Cross-reference**: Compare with manual validation data

### Performance Optimization Guidelines

#### For Large PDF Processing
- Use bulk processing: `python3 cat_flap_extractor_v5.py directory/ --format csv`
- Monitor memory usage during processing of 50+ files
- Consider chunked processing for very large datasets

#### For Web Application
- Pre-computed analytics in JSON format reduce client load
- Progressive loading: metadata first, detailed data on demand
- CloudFlare KV caching for frequently accessed data

#### For Testing
- Run subset tests during development: `pytest test_cat_flap_extractor.py::TestDurationParsing`
- Use `--debug` flag sparingly (verbose output)
- Parallel test execution for full suite validation

## Security Considerations for Developers

### Sensitive Data Handling
- **Never commit secrets**: Use `.env` files for local development
- **Email addresses**: Only authorized users in CloudFlare Workers
- **API tokens**: Stored as GitHub repository secrets
- **PDF content**: Temporary storage only, automatic cleanup

### Production Access
- **Web interface**: Magic link authentication required
- **GitHub Actions**: Automated workflows, no manual intervention needed
- **Data access**: Version-controlled datasets, full audit trail
- **Backup system**: Automatic with pruning, prevents data loss

## Monitoring and Maintenance

### Health Checks
- **Daily automated testing**: GitHub Actions runs test suite
- **Production monitoring**: Web interface availability
- **Data integrity**: Backup system with automatic pruning
- **Processing pipeline**: Email notifications for failures

### Regular Maintenance Tasks
- **Review test coverage**: Maintain >50% coverage threshold
- **Update dependencies**: Monitor for security updates
- **Clean temporary files**: `temp_outputs/` cleanup
- **Validate backups**: Ensure `dataset_backups/` pruning works correctly

### Scaling Considerations
- **Current capacity**: 1,573 records, tested up to 65+ PDF files
- **Growth projection**: Linear scaling for 5+ years
- **Migration triggers**: >50,000 records or complex queries
- **Database options**: CloudFlare D1 (SQLite) ready for future scaling

## Production Data Architecture Strategy

### Production Dataset Status
- **Current Size**: 1,573 sessions across 505+ days (live production data)
- **Source Files**: 65+ PDF reports in `BULK_PRODUCTIONDATA/`
- **Growth Rate**: ~40-50 sessions per week (predictable, linear growth)
- **5-Year Projection**: ~15,000 sessions (manageable with current architecture)
- **Storage Formats**: 
  - `master_dataset.csv` (334KB) - Primary data format
  - `master_dataset.json` (16KB) - Analytics-optimized format
  - Automatic backups in `dataset_backups/` with pruning (keeps 3 most recent)

### Architecture Decision: Enhanced CSV/JSON vs Database

#### Options Evaluated
- **SQLite/D1 Database**: Rejected due to complexity overhead for current dataset size
- **Pure Client-Side**: Rejected due to repeated computation overhead
- **Hybrid Approach**: Selected for optimal simplicity-to-performance ratio

### Hybrid CSV/JSON Implementation

**Enhanced JSON Structure with Pre-computed Analytics:**

```json
{
  "metadata": {
    "lastUpdated": "2025-06-23T19:00:00Z",
    "totalSessions": 1572,
    "dateRange": "2024-02-05 to 2025-06-22",
    "dataQuality": {
      "completeDays": 485,
      "partialDays": 20,
      "confidenceScore": 0.94
    }
  },
  "precomputed": {
    "dailySummaries": [
      {
        "date": "2024-02-05",
        "sessions": 4,
        "firstExit": "06:01",
        "lastEntry": "22:24",
        "totalOutdoorTime": "05:26",
        "isWeekend": false
      }
    ],
    "peakHours": [
      {"hour": 6, "exitFrequency": 0.45, "entryFrequency": 0.12},
      {"hour": 22, "exitFrequency": 0.15, "entryFrequency": 0.38}
    ],
    "seasonalStats": {
      "spring": {"avgDailySessions": 3.2, "avgFirstExit": "06:15"},
      "summer": {"avgDailySessions": 2.8, "avgFirstExit": "05:45"},
      "autumn": {"avgDailySessions": 3.5, "avgFirstExit": "06:45"},
      "winter": {"avgDailySessions": 3.1, "avgFirstExit": "07:15"}
    },
    "weekdayPatterns": {
      "weekdays": {"avgFirstExit": "06:30", "avgLastEntry": "22:15"},
      "weekends": {"avgFirstExit": "07:00", "avgLastEntry": "22:45"}
    }
  },
  "sessions": [...],     // Full session data for detailed analysis
  "annotations": [...]   // User annotations with date ranges
}
```

### Performance Benefits
- **Actogram Rendering**: Use dailySummaries (~365 records) vs full sessions (1,572 records)
- **Peak Hours Analysis**: Direct lookup from precomputed peakHours array
- **Pattern Detection**: Leverage weekdayPatterns and seasonalStats for instant comparison
- **Incremental Loading**: Load metadata + precomputed first, sessions on-demand

### Data Processing Pipeline
1. **GitHub Actions Enhancement**: Extend existing workflow to compute analytics
2. **Statistical Analysis**: Python scripts generate summaries during PDF processing
3. **JSON Generation**: Export enhanced JSON with precomputed analytics
4. **Client Optimization**: Progressive loading with smart caching strategies

### Architecture Advantages
- ✅ **Simplicity**: No database setup, familiar JSON structures
- ✅ **Transparency**: Raw data remains in version-controlled CSV/JSON
- ✅ **Performance**: Pre-computed analytics eliminate repeated calculations
- ✅ **Cost**: Zero additional hosting costs
- ✅ **Flexibility**: Easy migration to database later if dataset grows significantly
- ✅ **Offline Capability**: Client can cache and work without constant server connection

### Migration Path
If dataset grows beyond ~50,000 sessions or query complexity increases significantly, migration to CloudFlare D1 (SQLite) can be implemented with minimal client-side changes due to JSON API compatibility.

## Advanced Analytics Implementation (Phase 2)

### Web Dashboard Enhancement (Implemented)
- **Production Status**: Multi-page analytics dashboard operational
- **Routes Implemented**: `/dashboard`, `/patterns`, `/circadian`, `/upload`
- **Technology**: Material UI with responsive design
- **Analytics**: Real-time behavioral pattern analysis and visualization
- **Data Integration**: Live dataset updates via GitHub Actions pipeline

### Implemented Navigation Structure (Production)
```
Production Web App (cloudflare-workers/index.js - 29,685+ tokens) →
├── / (Home) - Landing page with authentication
├── /login - Magic link email authentication
├── /dashboard - Dataset status, statistics, download links
├── /upload - Drag-and-drop PDF processing interface
├── /patterns - Behavioral pattern analysis (IMPLEMENTED)
├── /circadian - Advanced circadian rhythm analytics (IMPLEMENTED)
└── API Endpoints:
    ├── /api/dataset - JSON data retrieval
    ├── /api/analytics - Pre-computed statistics
    └── /api/status - System health monitoring
```

### Analytics Processing Pipeline (Implemented)
- **Workflow**: `.github/workflows/process-pdf.yml` with analytics computation
- **Scripts**: `compute_analytics.py`, `rebuild_json_dataset.py` for statistics
- **Output**: Enhanced JSON with pre-computed metrics for dashboard performance
- **Real-time**: Immediate analytics updates when PDFs processed
- **Integration**: Seamless CloudFlare Workers ↔ GitHub Actions communication

## Quality Assurance (Production-Grade)

### Comprehensive Testing Strategy
- **Test Coverage**: 62 tests across 5 test files with 58% coverage
- **Daily Automation**: GitHub Actions testing workflow
- **Test Categories**:
  - **Unit Tests**: Duration parsing, timestamp analysis, exit/entry rules
  - **Integration Tests**: PDF processing, cross-year boundaries, data validation
  - **End-to-End Tests**: Full pipeline workflow, CloudFlare ↔ GitHub integration
  - **Regression Tests**: Critical functionality protection (prevents breaking changes)

### Production Data Validation
- **100% Accuracy**: Validated against manually corrected reference data
- **Cross-Year Processing**: December-January boundary handling implemented
- **Mathematical Precision**: Rules 3b/4b for complex long duration scenarios
- **Zero Data Loss**: Comprehensive error handling with automatic backups
- **Live Validation**: 1,573 records successfully processed and validated
- **Edge Case Coverage**: No-data periods, incomplete weeks, cross-midnight sessions

### Production Metrics (Live System)
- **Total Sessions Processed**: 1,573 validated sessions (live dataset)
- **PDF Reports Processed**: 65+ production files in `BULK_PRODUCTIONDATA/`
- **Date Range Coverage**: 505+ days (2024-02-05 to 2025-06-22)
- **Test Success Rate**: 100% (62/62 tests passing)
- **Processing Time**: Sub-minute processing for typical weekly reports
- **System Uptime**: Live at https://cat-flap-stats.herrings.workers.dev
- **Data Integrity**: Zero data loss with comprehensive backup system
- **Analytics Accuracy**: Cross-year boundary handling with mathematical precision

## Deployment Architecture

### Production System Components (Live)
- **Web Interface**: https://cat-flap-stats.herrings.workers.dev (Material UI, responsive)
- **Authentication**: Magic link email system using Resend API (authorized users only)
- **Processing**: GitHub Actions workflow (`.github/workflows/process-pdf.yml` - 334 lines)
- **Storage**: 
  - Primary: `master_dataset.csv` (1,573 records)
  - Backups: `dataset_backups/` with automatic pruning
  - Source: `BULK_PRODUCTIONDATA/` (65+ PDFs)
- **Notifications**: Resend email integration with detailed processing reports
- **CI/CD**: Automated testing (`.github/workflows/test.yml` - 61 lines)

### Security Considerations
- Magic link authentication (no passwords stored)
- CloudFlare and GitHub secrets management
- Secure API token handling
- Session management with automatic expiration
- Version-controlled data with backup protection

## Performance Optimization

### Production Performance Characteristics
- **Dataset Size**: 334KB CSV, 16KB JSON (1,573 records)
- **Processing Time**: <60 seconds per PDF via GitHub Actions
- **Memory Usage**: In-memory processing optimal for current 1,573 record scale
- **Network**: Fast download times, CloudFlare CDN distribution
- **Bulk Processing**: Successfully handles 65+ PDF directory processing
- **Analytics Computation**: Real-time statistics generation during processing
- **Backup Performance**: Automatic pruning maintains 3 most recent versions

## Project File Structure (Production)

### Core Application Files
```
cat_flap_extractor_v5.py        # Main extractor (1,155 lines)
cloudflare-workers/index.js      # Web application (29,685+ tokens)
requirements.txt                 # Python dependencies
wrangler.toml                    # CloudFlare configuration
```

### Data Management
```
master_dataset.csv               # Live production dataset (1,573 records)
master_dataset.json              # Analytics-optimized format
dataset_backups/                 # Automatic backups (3 most recent)
BULK_PRODUCTIONDATA/            # 65+ source PDF files
SAMPLEDATA/                     # 7 sample PDFs for testing
SAMPLE_TESTDATA/                # 21 test PDFs for validation
temp_outputs/                   # Generated analysis files
```

### Testing Infrastructure
```
test_cat_flap_extractor.py      # Main test suite
test_critical_functionality.py  # Regression protection
test_merge_datasets.py          # Dataset merging validation
test_backup_system.py           # Backup system testing
test_long_duration_fix.py       # Edge case validation
```

### CI/CD & Automation
```
.github/workflows/
├── process-pdf.yml             # Main processing workflow (334 lines)
├── test.yml                    # Testing workflow (61 lines)
└── scripts/
    ├── merge_datasets.py       # Duplicate detection & merging
    ├── compute_analytics.py    # Analytics computation
    └── rebuild_json_dataset.py # JSON reconstruction
```

### Development Utilities
```
debug_scripts/                  # 7 debug utilities
archive/                        # Previous extractor versions (v1-v4)
```

## Scalability Considerations (Production-Tested)
- **Current Scale**: 1,573 records processed successfully
- **Linear Growth**: Manageable for 5+ years (projected 15,000 records)
- **Pre-computed Analytics**: JSON format with real-time statistics
- **Progressive Loading**: Metadata-first strategy implemented
- **Database Migration**: CloudFlare D1 path available for >50,000 records
- **Performance Optimization**: Proven with 65+ PDF bulk processing