name: Process Cat Flap PDF

on:
  repository_dispatch:
    types: [process-pdf]

jobs:
  process-pdf:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Allow writing to repository contents
      
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python 3.13
      uses: actions/setup-python@v4
      with:
        python-version: '3.13'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Download PDF from CloudFlare KV
      env:
        CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        KV_NAMESPACE_ID: ${{ secrets.KV_NAMESPACE_ID }}
      run: |
        # Extract file ID from webhook payload
        FILE_ID="${{ github.event.client_payload.file_id }}"
        FILENAME="${{ github.event.client_payload.filename }}"
        
        echo "Processing file: $FILENAME (ID: $FILE_ID)"
        echo "CloudFlare Account ID: $CLOUDFLARE_ACCOUNT_ID"
        echo "KV Namespace ID: $KV_NAMESPACE_ID"
        echo "API Token length: ${#CLOUDFLARE_API_TOKEN} characters"
        
        # Download PDF from CloudFlare KV using REST API
        echo "Downloading from CloudFlare KV..."
        HTTP_RESPONSE=$(curl -w "%{http_code}" -X GET \
          "https://api.cloudflare.com/client/v4/accounts/$CLOUDFLARE_ACCOUNT_ID/storage/kv/namespaces/$KV_NAMESPACE_ID/values/upload:$FILE_ID" \
          -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
          -H "Accept: application/octet-stream" \
          --output "temp_upload.pdf" \
          --silent)
        
        echo "HTTP Response Code: $HTTP_RESPONSE"
        
        # Check if download was successful
        if [ "$HTTP_RESPONSE" != "200" ]; then
          echo "CloudFlare API request failed with HTTP $HTTP_RESPONSE"
          echo "Response content:"
          cat temp_upload.pdf
          exit 1
        fi
        
        # Verify PDF was downloaded and is a reasonable size
        FILE_SIZE=$(wc -c < temp_upload.pdf)
        echo "Downloaded file size: $FILE_SIZE bytes"
        
        if [ ! -f "temp_upload.pdf" ]; then
          echo "Failed to download PDF file"
          exit 1
        fi
        
        if [ "$FILE_SIZE" -lt 1000 ]; then
          echo "Downloaded file is too small ($FILE_SIZE bytes) - likely an error response"
          echo "File contents:"
          cat temp_upload.pdf
          exit 1
        fi
        
        # Check if it's actually a PDF file
        file temp_upload.pdf
        
        echo "PDF downloaded successfully: $FILE_SIZE bytes"
        
    - name: Process PDF with extractor
      run: |
        echo "Processing PDF with cat_flap_extractor_v5.py"
        echo "Current directory: $(pwd)"
        echo "Files in current directory:"
        ls -la
        echo "Python files available:"
        ls -la *.py || echo "No Python files found"
        echo "Checking if extractor exists:"
        ls -la cat_flap_extractor_v5.py || echo "Extractor not found"
        echo "PDF file to process:"
        ls -la temp_upload.pdf
        echo "Starting extraction..."
        
        # Run the extractor on the downloaded PDF and capture output
        EXTRACTOR_OUTPUT=$(python3 cat_flap_extractor_v5.py temp_upload.pdf --format both --output processed_data 2>&1)
        EXTRACTOR_EXIT_CODE=$?
        
        echo "Extractor output:"
        echo "$EXTRACTOR_OUTPUT"
        echo "Extractor exit code: $EXTRACTOR_EXIT_CODE"
        
        echo "Checking output files..."
        ls -la processed_data* || echo "No processed_data files found"
        
        # Check if extractor reported no data
        if echo "$EXTRACTOR_OUTPUT" | grep -q "No data extracted"; then
          echo "PDF contains no cat flap usage data - creating empty output files"
          
          # Create empty CSV with headers
          echo "filename,report_date,report_date_range,report_year,pet_name,age,weight,date_str,date_full,session_number,exit_time,entry_time,duration,daily_total_visits_PDF,daily_total_time_outside_PDF,daily_total_visits_calculated,daily_total_time_outside_calculated,extracted_at" > processed_data.csv
          
          # Create empty JSON with metadata
          echo '{
            "metadata": {
              "filename": "temp_upload.pdf",
              "extraction_status": "no_data",
              "extraction_note": "PDF contains no cat flap usage data",
              "total_sessions": 0,
              "generated_at": "'$(date -u +%Y-%m-%dT%H:%M:%S.%6NZ)'"
            },
            "sessions": []
          }' > processed_data.json
          
          echo "Empty output files created for PDF with no data"
        elif [ ! -f "processed_data.csv" ] || [ ! -f "processed_data.json" ]; then
          echo "PDF processing failed - output files not found and no 'No data extracted' message"
          echo "Contents of directory after processing:"
          ls -la
          exit 1
        fi
        
        echo "PDF processing completed"
        if [ -f "processed_data.csv" ]; then
          echo "CSV file size: $(wc -c < processed_data.csv) bytes"
        fi
        if [ -f "processed_data.json" ]; then
          echo "JSON file size: $(wc -c < processed_data.json) bytes"
        fi
        
    - name: Backup existing dataset
      run: |
        # Create backup directory with timestamp
        TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
        mkdir -p "dataset_backups/$TIMESTAMP"
        
        # Backup existing dataset files if they exist
        if [ -f "master_dataset.csv" ]; then
          cp master_dataset.csv "dataset_backups/$TIMESTAMP/"
          echo "Backed up existing CSV dataset"
        fi
        
        if [ -f "master_dataset.json" ]; then
          cp master_dataset.json "dataset_backups/$TIMESTAMP/"
          echo "Backed up existing JSON dataset"
        fi
        
    - name: Check for duplicates and merge with master dataset
      run: |
        echo "Checking for duplicates and merging with master dataset"
        
        # Run the dataset merge script (handles both CSV and JSON)
        python3 .github/scripts/merge_datasets.py
        
        echo "Dataset merge completed"
        echo "Final CSV size: $(wc -c < master_dataset.csv) bytes"
        echo "Final JSON size: $(wc -c < master_dataset.json) bytes"
        
    - name: Generate processing report
      run: |
        echo "Generating processing report..."
        
        # Create processing report using echo statements to avoid YAML issues
        echo "# PDF Processing Report" > processing_report.md
        echo "" >> processing_report.md
        echo "**Date:** $(date)" >> processing_report.md
        echo "**File:** ${{ github.event.client_payload.filename }}" >> processing_report.md
        echo "**Uploaded by:** ${{ github.event.client_payload.uploaded_by }}" >> processing_report.md
        echo "" >> processing_report.md
        echo "## Processing Results" >> processing_report.md
        echo "- ‚úÖ PDF downloaded successfully" >> processing_report.md
        
        # Check if this was an empty PDF (no data)
        if grep -q "PDF contained no cat flap usage data" duplicate_report.txt; then
          echo "- ‚ÑπÔ∏è PDF contained no cat flap usage data" >> processing_report.md
          echo "- ‚úÖ Empty file processing completed" >> processing_report.md
          echo "- ‚úÖ Dataset backup created" >> processing_report.md
          echo "- ‚úÖ Processing report generated" >> processing_report.md
        else
          echo "- ‚úÖ Data extraction completed" >> processing_report.md
          echo "- ‚úÖ Duplicate detection performed" >> processing_report.md
          echo "- ‚úÖ Dataset backup created" >> processing_report.md
          echo "- ‚úÖ Master dataset updated" >> processing_report.md
        fi
        
        echo "" >> processing_report.md
        echo "## Duplicate Detection" >> processing_report.md
        cat duplicate_report.txt >> processing_report.md
        echo "" >> processing_report.md
        echo "## File Statistics" >> processing_report.md
        echo "- New CSV size: $(wc -c < processed_data.csv) bytes" >> processing_report.md
        echo "- New JSON size: $(wc -c < processed_data.json) bytes" >> processing_report.md
        echo "- Master CSV size: $(wc -c < master_dataset.csv) bytes" >> processing_report.md
        echo "- Master JSON size: $(wc -c < master_dataset.json) bytes" >> processing_report.md
        echo "" >> processing_report.md
        
        echo "Processing report generated successfully"
        
    - name: Commit updated dataset
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        # Configure git
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Add files to git
        git add master_dataset.csv master_dataset.json dataset_backups/ processing_report.md
        
        # Check if there are changes to commit
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          # Commit changes
          git commit -m "üìä Update dataset: processed ${{ github.event.client_payload.filename }} - uploaded by ${{ github.event.client_payload.uploaded_by }} - ü§ñ Automated processing via GitHub Actions"
          
          # Push changes
          git push
          
          echo "Dataset successfully updated and committed"
        fi
        
    - name: Send notification email
      env:
        RESEND_API_KEY: ${{ secrets.RESEND_API_KEY }}
      run: |
        # Check if this was an empty PDF and customize email accordingly
        if grep -q "PDF contained no cat flap usage data" duplicate_report.txt; then
          # Email for empty PDF
          EMAIL_SUBJECT="‚ÑπÔ∏è PDF Processed (No Data) - ${{ github.event.client_payload.filename }}"
          EMAIL_HTML="<h2>PDF Processing Complete</h2><p>Your file <strong>${{ github.event.client_payload.filename }}</strong> has been processed successfully.</p><p><strong>Result:</strong> This PDF contained no cat flap usage data (Sven didn't use the cat flap during this period).</p><p>The master dataset remains unchanged. This is normal for periods when your cat doesn't use the flap.</p><p><a href=\"https://cat-flap-stats.herrings.workers.dev/dashboard\">View Dashboard</a></p>"
          EMAIL_TEXT="PDF Processing Complete! Your file ${{ github.event.client_payload.filename }} has been processed. Result: No cat flap usage data found in this PDF (normal for inactive periods). The dataset remains unchanged."
        else
          # Email for PDF with data
          EMAIL_SUBJECT="‚úÖ PDF Processing Complete - ${{ github.event.client_payload.filename }}"
          EMAIL_HTML="<h2>PDF Processing Successful</h2><p>Your file <strong>${{ github.event.client_payload.filename }}</strong> has been processed successfully.</p><p>The master dataset has been updated with new cat flap usage data and is available for download.</p><p><a href=\"https://cat-flap-stats.herrings.workers.dev/dashboard\">View Dashboard</a></p>"
          EMAIL_TEXT="PDF Processing Complete! Your file ${{ github.event.client_payload.filename }} has been processed and the dataset has been updated with new data. Visit the dashboard to download the latest data."
        fi
        
        # Send processing completion email
        curl -X POST "https://api.resend.com/emails" \
          -H "Authorization: Bearer $RESEND_API_KEY" \
          -H "Content-Type: application/json" \
          -d "{
            \"from\": \"Cat Flap Stats <noreply@echoreflex.me>\",
            \"to\": [\"${{ github.event.client_payload.uploaded_by }}\"],
            \"subject\": \"$EMAIL_SUBJECT\",
            \"html\": \"$EMAIL_HTML\",
            \"text\": \"$EMAIL_TEXT\"
          }"
        
        echo "Notification email sent"
        
    - name: Clean up temporary files
      run: |
        # Remove temporary files
        rm -f temp_upload.pdf processed_data.csv processed_data.json
        echo "Temporary files cleaned up"